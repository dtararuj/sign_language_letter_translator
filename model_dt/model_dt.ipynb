{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "948bac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras import layers\n",
    "import datetime\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a94cfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_parent =os.path.dirname(os. getcwd())\n",
    "os.chdir(path_parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "696547e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dawid\\Desktop\\kurs\\jdszr4-animalsi\\gesty\\model_dt\n"
     ]
    }
   ],
   "source": [
    "from preprocessing.dane import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0882043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ustawienie wlasciwego ksztaltu danych wejsciowych\n",
    "X_train = X_train.reshape(-1,28,28,1)\n",
    "X_test = X_test.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d25701c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definicja tensoboard callback\n",
    "log_dir = \"logs\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46990f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logs\\\\20211029-184335'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6dab98c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definicja modelu\n",
    "\n",
    "def create_model(X, Y,filters, dropout: float, units, class_num, lr = 0.001, epochs = 20, batch = 256, plot = True  ):\n",
    "    \n",
    "    '''\n",
    "    X - our training dataset without labels,\n",
    "    Y - labels from our training dataset\n",
    "    filters - list of filters,\n",
    "    dropout - value, float, representing size of dropout after each convolution layer,\n",
    "    units - list of units in DenseLayer,\n",
    "    class_num - how many classes we have in our dataset\n",
    "    lr - learning rate used in optimizer \"Adam\", default 0.001,\n",
    "    epochs - number of epoch\n",
    "    batch - batch size, default 256\n",
    "    plot - if True then print plot\n",
    "    '''\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    model.add(layers.InputLayer(input_shape= X.shape[1:]))\n",
    "    \n",
    "    for i, j in enumerate(filters):\n",
    "        model.add(layers.Conv2D(\n",
    "            filters = j,\n",
    "            kernel_size = (3,3),\n",
    "            strides = 1,\n",
    "            padding = 'same', \n",
    "            activation = 'relu',\n",
    "            input_shape = (-1,28,28,1)))  \n",
    "        \n",
    "        model.add(layers.MaxPool2D(\n",
    "            pool_size = 2,\n",
    "            strides = 2,\n",
    "            padding = 'same',\n",
    "            name = \"warstwaCNN\" + str(i)))\n",
    "    \n",
    "        model.add(layers.Dropout(dropout))\n",
    "        \n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    for a,b in enumerate(units):\n",
    "        model.add(layers.Dense(\n",
    "            b,\n",
    "            activation = 'relu',\n",
    "            name = \"warstwa_gesta\" + str(a)))\n",
    "        \n",
    "        model.add(layers.Dropout(dropout))\n",
    "    \n",
    "    model.add(layers.Dense(class_num, name = 'wyjscie'))\n",
    "    model.add(layers.Softmax())\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "                  \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "                  \n",
    "    model.compile(\n",
    "            optimizer = opt,\n",
    "            loss = 'categorical_crossentropy',\n",
    "            metrics = ['accuracy'])\n",
    "        \n",
    "    results = model.fit(\n",
    "            X,\n",
    "            Y,\n",
    "            epochs = epochs,\n",
    "            batch_size = batch,\n",
    "            validation_split= 0.2,\n",
    "            callbacks = [tf.keras.callbacks.EarlyStopping(patience= 3),\n",
    "                        tensorboard_callback])\n",
    "    \n",
    "    if plot == True:\n",
    "        plt.figure(figsize = (15,7))\n",
    "        plt.plot(results.history['accuracy'], label = 'train')\n",
    "        plt.plot(results.history['val_accuracy'], label = 'val')\n",
    "        plt.show()\n",
    "    else:\n",
    "        None\n",
    "    \n",
    "    return model               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5de40e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "warstwaCNN0 (MaxPooling2D)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "warstwaCNN1 (MaxPooling2D)   (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "warstwa_gesta0 (Dense)       (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "warstwa_gesta1 (Dense)       (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "wyjscie (Dense)              (None, 24)                1560      \n",
      "_________________________________________________________________\n",
      "softmax_5 (Softmax)          (None, 24)                0         \n",
      "=================================================================\n",
      "Total params: 839,896\n",
      "Trainable params: 839,896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "86/86 [==============================] - 57s 616ms/step - loss: 2.5721 - accuracy: 0.2383 - val_loss: 1.2471 - val_accuracy: 0.6514\n",
      "Epoch 2/20\n",
      "86/86 [==============================] - 55s 644ms/step - loss: 0.9634 - accuracy: 0.6852 - val_loss: 0.3836 - val_accuracy: 0.8977\n",
      "Epoch 3/20\n",
      "86/86 [==============================] - 49s 572ms/step - loss: 0.4664 - accuracy: 0.8419 - val_loss: 0.1695 - val_accuracy: 0.9590\n",
      "Epoch 4/20\n",
      "86/86 [==============================] - 43s 497ms/step - loss: 0.2458 - accuracy: 0.9216 - val_loss: 0.0656 - val_accuracy: 0.9907\n",
      "Epoch 5/20\n",
      "86/86 [==============================] - 42s 493ms/step - loss: 0.1455 - accuracy: 0.9552 - val_loss: 0.0371 - val_accuracy: 0.9971\n",
      "Epoch 6/20\n",
      "86/86 [==============================] - 47s 544ms/step - loss: 0.0956 - accuracy: 0.9705 - val_loss: 0.0135 - val_accuracy: 0.9996\n",
      "Epoch 7/20\n",
      "86/86 [==============================] - 48s 564ms/step - loss: 0.0679 - accuracy: 0.9801 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "86/86 [==============================] - 161s 2s/step - loss: 0.0454 - accuracy: 0.9873 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "86/86 [==============================] - 43s 507ms/step - loss: 0.0371 - accuracy: 0.9909 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "86/86 [==============================] - 53s 616ms/step - loss: 0.0288 - accuracy: 0.9927 - val_loss: 0.0030 - val_accuracy: 0.9996\n",
      "Epoch 11/20\n",
      "86/86 [==============================] - 51s 591ms/step - loss: 0.0281 - accuracy: 0.9923 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "86/86 [==============================] - 47s 543ms/step - loss: 0.0195 - accuracy: 0.9948 - val_loss: 8.3984e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "86/86 [==============================] - 42s 488ms/step - loss: 0.0174 - accuracy: 0.9952 - val_loss: 7.3849e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "86/86 [==============================] - 40s 465ms/step - loss: 0.0144 - accuracy: 0.9964 - val_loss: 5.1697e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "86/86 [==============================] - 46s 533ms/step - loss: 0.0112 - accuracy: 0.9977 - val_loss: 4.7925e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "86/86 [==============================] - 44s 509ms/step - loss: 0.0114 - accuracy: 0.9975 - val_loss: 5.2404e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "86/86 [==============================] - 43s 507ms/step - loss: 0.0123 - accuracy: 0.9962 - val_loss: 4.4759e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "86/86 [==============================] - 45s 529ms/step - loss: 0.0098 - accuracy: 0.9974 - val_loss: 5.3009e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "86/86 [==============================] - 43s 497ms/step - loss: 0.0114 - accuracy: 0.9967 - val_loss: 7.4008e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "86/86 [==============================] - 42s 492ms/step - loss: 0.0105 - accuracy: 0.9971 - val_loss: 7.7676e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#wywolanie modelu\n",
    "model1 = create_model(X_train, Y_train,[32, 64], 0.1,[256,64],24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2679b067",
   "metadata": {},
   "source": [
    "Jak widzimy nasz model osiagnał bardzo wysoka dokladnosc na zbiorze treningowym i walidacyjnym juz w 5 epoce.  \n",
    "Sprawdzmy jakie wyniki uzyskamy na zbiorze testowym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f5a02c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       331\n",
      "           1       1.00      0.95      0.97       432\n",
      "           2       1.00      0.93      0.96       310\n",
      "           3       0.86      1.00      0.92       245\n",
      "           4       0.96      1.00      0.98       498\n",
      "           5       1.00      1.00      1.00       247\n",
      "           6       0.94      0.97      0.96       348\n",
      "           7       0.99      0.95      0.97       436\n",
      "           8       0.93      0.93      0.93       288\n",
      "           9       0.98      0.93      0.96       331\n",
      "          10       0.94      1.00      0.97       209\n",
      "          11       1.00      0.89      0.94       394\n",
      "          12       0.92      0.79      0.85       291\n",
      "          13       0.92      1.00      0.96       246\n",
      "          14       0.99      1.00      1.00       347\n",
      "          15       0.99      1.00      1.00       164\n",
      "          16       0.79      0.72      0.75       144\n",
      "          17       0.89      0.91      0.90       246\n",
      "          18       0.94      0.74      0.83       248\n",
      "          19       0.92      0.90      0.91       266\n",
      "          20       0.94      0.95      0.95       346\n",
      "          21       0.84      1.00      0.91       206\n",
      "          22       0.74      1.00      0.85       267\n",
      "          23       0.94      0.87      0.90       332\n",
      "\n",
      "    accuracy                           0.94      7172\n",
      "   macro avg       0.93      0.94      0.93      7172\n",
      "weighted avg       0.94      0.94      0.94      7172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predykcja\n",
    "y_pred1 = model1.predict(X_test).argmax(axis = 1)\n",
    "\n",
    "print(classification_report(Y_test.argmax(axis = 1), y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf013cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1 accuracy =  0.94\n"
     ]
    }
   ],
   "source": [
    "acc1 = accuracy_score(y_pred1, Y_test.argmax(axis = 1))\n",
    "print('model1 accuracy = ', round(acc1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f89102a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "warstwaCNN0 (MaxPooling2D)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "warstwaCNN1 (MaxPooling2D)   (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "warstwaCNN2 (MaxPooling2D)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "warstwa_gesta0 (Dense)       (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "warstwa_gesta1 (Dense)       (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "wyjscie (Dense)              (None, 24)                1560      \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 24)                0         \n",
      "=================================================================\n",
      "Total params: 635,224\n",
      "Trainable params: 635,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "86/86 [==============================] - 43s 493ms/step - loss: 2.6820 - accuracy: 0.2012 - val_loss: 1.5224 - val_accuracy: 0.5148\n",
      "Epoch 2/20\n",
      "86/86 [==============================] - 43s 495ms/step - loss: 0.9106 - accuracy: 0.6962 - val_loss: 0.3736 - val_accuracy: 0.8973\n",
      "Epoch 3/20\n",
      "86/86 [==============================] - 43s 499ms/step - loss: 0.2991 - accuracy: 0.9027 - val_loss: 0.1068 - val_accuracy: 0.9800\n",
      "Epoch 4/20\n",
      "86/86 [==============================] - 42s 485ms/step - loss: 0.1310 - accuracy: 0.9605 - val_loss: 0.0525 - val_accuracy: 0.9882\n",
      "Epoch 5/20\n",
      "86/86 [==============================] - 42s 494ms/step - loss: 0.0684 - accuracy: 0.9806 - val_loss: 0.0204 - val_accuracy: 0.9973\n",
      "Epoch 6/20\n",
      "86/86 [==============================] - 42s 490ms/step - loss: 0.0385 - accuracy: 0.9903 - val_loss: 0.0084 - val_accuracy: 0.9998\n",
      "Epoch 7/20\n",
      "86/86 [==============================] - 42s 492ms/step - loss: 0.0303 - accuracy: 0.9912 - val_loss: 0.0107 - val_accuracy: 0.9967\n",
      "Epoch 8/20\n",
      "86/86 [==============================] - 43s 503ms/step - loss: 0.0228 - accuracy: 0.9942 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "86/86 [==============================] - 42s 488ms/step - loss: 0.0166 - accuracy: 0.9963 - val_loss: 0.0032 - val_accuracy: 0.9996\n",
      "Epoch 10/20\n",
      "86/86 [==============================] - 53s 612ms/step - loss: 0.0122 - accuracy: 0.9975 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "86/86 [==============================] - 54s 630ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 9.2194e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "86/86 [==============================] - 52s 598ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 7.6250e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "86/86 [==============================] - 53s 613ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 6.8885e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "86/86 [==============================] - 51s 590ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.0014 - val_accuracy: 0.9998\n",
      "Epoch 15/20\n",
      "86/86 [==============================] - 50s 577ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.0016 - val_accuracy: 0.9996\n",
      "Epoch 16/20\n",
      "86/86 [==============================] - 59s 689ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 4.9379e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "86/86 [==============================] - 179s 2s/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 9.1630e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "86/86 [==============================] - 48s 557ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 0.0029 - val_accuracy: 0.9996\n",
      "Epoch 19/20\n",
      "86/86 [==============================] - 44s 510ms/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 6.5606e-04 - val_accuracy: 0.9998\n",
      "model2 accuracy =  0.95\n"
     ]
    }
   ],
   "source": [
    "#wywolanie modelu2\n",
    "model2 = create_model(X_train, Y_train,[32, 64,128], 0.1,[256,64],24, plot = False)\n",
    "\n",
    "#predykcja\n",
    "y_pred2 = model2.predict(X_test).argmax(axis = 1)\n",
    "\n",
    "acc2 = accuracy_score(y_pred2, Y_test.argmax(axis = 1))\n",
    "print('model2 accuracy = ', round(acc2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e42f2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model3 accuracy =  0.94\n"
     ]
    }
   ],
   "source": [
    "#wywolanie modelu3\n",
    "model3 = create_model(X_train, Y_train,[32, 64,128], 0.1,[512,256,64],24, plot = False)\n",
    "\n",
    "#predykcja\n",
    "y_pred3 = model3.predict(X_test).argmax(axis = 1)\n",
    "\n",
    "acc3 = accuracy_score(y_pred3, Y_test.argmax(axis = 1))\n",
    "print('model3 accuracy = ', round(acc3,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cbbefc",
   "metadata": {},
   "source": [
    "Jak widzimy, dodawanie kolejnych wartstw gestych nie poprawia wyniku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "617ec4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "warstwaCNN0 (MaxPooling2D)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "warstwaCNN1 (MaxPooling2D)   (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "warstwaCNN2 (MaxPooling2D)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "warstwa_gesta0 (Dense)       (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "warstwa_gesta1 (Dense)       (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "wyjscie (Dense)              (None, 24)                1560      \n",
      "_________________________________________________________________\n",
      "softmax_4 (Softmax)          (None, 24)                0         \n",
      "=================================================================\n",
      "Total params: 635,224\n",
      "Trainable params: 635,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "86/86 [==============================] - 52s 572ms/step - loss: 3.0546 - accuracy: 0.0822 - val_loss: 2.3350 - val_accuracy: 0.3182\n",
      "Epoch 2/20\n",
      "86/86 [==============================] - 48s 554ms/step - loss: 1.6012 - accuracy: 0.4741 - val_loss: 0.6648 - val_accuracy: 0.8161\n",
      "Epoch 3/20\n",
      "86/86 [==============================] - 47s 552ms/step - loss: 0.6961 - accuracy: 0.7587 - val_loss: 0.2496 - val_accuracy: 0.9350\n",
      "Epoch 4/20\n",
      "86/86 [==============================] - 49s 571ms/step - loss: 0.3803 - accuracy: 0.8691 - val_loss: 0.0917 - val_accuracy: 0.9805\n",
      "Epoch 5/20\n",
      "86/86 [==============================] - 48s 555ms/step - loss: 0.2304 - accuracy: 0.9218 - val_loss: 0.0368 - val_accuracy: 0.9958\n",
      "Epoch 6/20\n",
      "86/86 [==============================] - 48s 563ms/step - loss: 0.1559 - accuracy: 0.9493 - val_loss: 0.0163 - val_accuracy: 0.9995\n",
      "Epoch 7/20\n",
      "86/86 [==============================] - 48s 554ms/step - loss: 0.1100 - accuracy: 0.9633 - val_loss: 0.0081 - val_accuracy: 0.9993\n",
      "Epoch 8/20\n",
      "86/86 [==============================] - 47s 549ms/step - loss: 0.0799 - accuracy: 0.9749 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "86/86 [==============================] - 49s 570ms/step - loss: 0.0636 - accuracy: 0.9805 - val_loss: 0.0025 - val_accuracy: 0.9998\n",
      "Epoch 10/20\n",
      "86/86 [==============================] - 47s 550ms/step - loss: 0.0523 - accuracy: 0.9836 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "86/86 [==============================] - 48s 562ms/step - loss: 0.0391 - accuracy: 0.9885 - val_loss: 9.0672e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "86/86 [==============================] - 48s 556ms/step - loss: 0.0389 - accuracy: 0.9879 - val_loss: 9.6665e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "86/86 [==============================] - 47s 549ms/step - loss: 0.0330 - accuracy: 0.9894 - val_loss: 7.4315e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "86/86 [==============================] - 49s 568ms/step - loss: 0.0302 - accuracy: 0.9895 - val_loss: 6.5686e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "86/86 [==============================] - 47s 551ms/step - loss: 0.0255 - accuracy: 0.9922 - val_loss: 1.9336e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "86/86 [==============================] - 49s 566ms/step - loss: 0.0222 - accuracy: 0.9934 - val_loss: 4.1691e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "86/86 [==============================] - 48s 555ms/step - loss: 0.0171 - accuracy: 0.9950 - val_loss: 1.1949e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "86/86 [==============================] - 47s 548ms/step - loss: 0.0180 - accuracy: 0.9947 - val_loss: 4.1020e-04 - val_accuracy: 0.9998\n",
      "Epoch 19/20\n",
      "86/86 [==============================] - 49s 571ms/step - loss: 0.0170 - accuracy: 0.9953 - val_loss: 1.3470e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "86/86 [==============================] - 47s 550ms/step - loss: 0.0167 - accuracy: 0.9945 - val_loss: 3.1896e-04 - val_accuracy: 0.9998\n",
      "model3 accuracy =  0.98\n"
     ]
    }
   ],
   "source": [
    "#wywolanie modelu4\n",
    "model4 = create_model(X_train, Y_train,[32, 64, 128], 0.2,[256,64],24, plot = False)\n",
    "\n",
    "#predykcja\n",
    "y_pred4 = model4.predict(X_test).argmax(axis = 1)\n",
    "\n",
    "acc4 = accuracy_score(y_pred4, Y_test.argmax(axis = 1))\n",
    "print('model4 accuracy = ', round(acc4,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910154b4",
   "metadata": {},
   "source": [
    "Zwiększając współczynnik dropoutu uzyskaliśmy całkiem dobry wynik na zbiorze testowym, 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3133440e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "warstwaCNN0 (MaxPooling2D)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "warstwaCNN1 (MaxPooling2D)   (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "warstwaCNN2 (MaxPooling2D)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "warstwa_gesta0 (Dense)       (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "warstwa_gesta1 (Dense)       (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "wyjscie (Dense)              (None, 24)                1560      \n",
      "_________________________________________________________________\n",
      "softmax_6 (Softmax)          (None, 24)                0         \n",
      "=================================================================\n",
      "Total params: 635,224\n",
      "Trainable params: 635,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "86/86 [==============================] - 55s 592ms/step - loss: 3.0183 - accuracy: 0.0898 - val_loss: 2.1527 - val_accuracy: 0.3682\n",
      "Epoch 2/20\n",
      "86/86 [==============================] - 48s 562ms/step - loss: 1.6574 - accuracy: 0.4469 - val_loss: 0.7564 - val_accuracy: 0.7787\n",
      "Epoch 3/20\n",
      "86/86 [==============================] - 49s 571ms/step - loss: 0.8628 - accuracy: 0.7006 - val_loss: 0.3024 - val_accuracy: 0.9177\n",
      "Epoch 4/20\n",
      "86/86 [==============================] - 49s 566ms/step - loss: 0.5186 - accuracy: 0.8187 - val_loss: 0.1396 - val_accuracy: 0.9678\n",
      "Epoch 5/20\n",
      "86/86 [==============================] - 48s 560ms/step - loss: 0.3465 - accuracy: 0.8798 - val_loss: 0.0635 - val_accuracy: 0.9900\n",
      "Epoch 6/20\n",
      "86/86 [==============================] - 48s 564ms/step - loss: 0.2461 - accuracy: 0.9155 - val_loss: 0.0368 - val_accuracy: 0.9969\n",
      "Epoch 7/20\n",
      "86/86 [==============================] - 48s 558ms/step - loss: 0.1807 - accuracy: 0.9396 - val_loss: 0.0142 - val_accuracy: 0.9991\n",
      "Epoch 8/20\n",
      "86/86 [==============================] - 48s 557ms/step - loss: 0.1423 - accuracy: 0.9522 - val_loss: 0.0088 - val_accuracy: 0.9987\n",
      "Epoch 9/20\n",
      "86/86 [==============================] - 48s 564ms/step - loss: 0.1238 - accuracy: 0.9592 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "86/86 [==============================] - 48s 559ms/step - loss: 0.0999 - accuracy: 0.9677 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "86/86 [==============================] - 48s 558ms/step - loss: 0.0799 - accuracy: 0.9738 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "86/86 [==============================] - 48s 558ms/step - loss: 0.0707 - accuracy: 0.9779 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "86/86 [==============================] - 48s 560ms/step - loss: 0.0592 - accuracy: 0.9814 - val_loss: 7.6074e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "86/86 [==============================] - 48s 558ms/step - loss: 0.0517 - accuracy: 0.9844 - val_loss: 7.5018e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "86/86 [==============================] - 48s 562ms/step - loss: 0.0485 - accuracy: 0.9843 - val_loss: 4.6530e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "86/86 [==============================] - 48s 563ms/step - loss: 0.0435 - accuracy: 0.9863 - val_loss: 3.2868e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "86/86 [==============================] - 48s 559ms/step - loss: 0.0397 - accuracy: 0.9881 - val_loss: 2.6520e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "86/86 [==============================] - 48s 558ms/step - loss: 0.0363 - accuracy: 0.9883 - val_loss: 1.5623e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "86/86 [==============================] - 48s 560ms/step - loss: 0.0322 - accuracy: 0.9893 - val_loss: 1.4508e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "86/86 [==============================] - 48s 559ms/step - loss: 0.0283 - accuracy: 0.9914 - val_loss: 9.2668e-05 - val_accuracy: 1.0000\n",
      "model5 accuracy =  0.97\n"
     ]
    }
   ],
   "source": [
    "#wywolanie modelu 5\n",
    "model5 = create_model(X_train, Y_train,[32, 64, 128], 0.3,[256,64],24, plot = False)\n",
    "\n",
    "#predykcja\n",
    "y_pred5 = model5.predict(X_test).argmax(axis = 1)\n",
    "\n",
    "acc5 = accuracy_score(y_pred5, Y_test.argmax(axis = 1))\n",
    "print('model5 accuracy = ', round(acc5,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b33b3c",
   "metadata": {},
   "source": [
    "Kolejne podwyzszenie dropout nie poprawilo nam wyników, spróbujmy jesszcze zastosować residual blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "837b1c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_23 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "warstwaCNN0 (MaxPooling2D)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "warstwaCNN1 (MaxPooling2D)   (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "warstwaCNN2 (MaxPooling2D)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "warstwaCNN3 (MaxPooling2D)   (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "warstwa_gesta0 (Dense)       (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "warstwa_gesta1 (Dense)       (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "wyjscie (Dense)              (None, 24)                3096      \n",
      "_________________________________________________________________\n",
      "softmax_7 (Softmax)          (None, 24)                0         \n",
      "=================================================================\n",
      "Total params: 981,400\n",
      "Trainable params: 981,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "86/86 [==============================] - 82s 910ms/step - loss: 3.1481 - accuracy: 0.0601 - val_loss: 2.7183 - val_accuracy: 0.1916\n",
      "Epoch 2/20\n",
      "86/86 [==============================] - 78s 903ms/step - loss: 1.8137 - accuracy: 0.4048 - val_loss: 0.8147 - val_accuracy: 0.7412\n",
      "Epoch 3/20\n",
      "86/86 [==============================] - 78s 908ms/step - loss: 0.6740 - accuracy: 0.7623 - val_loss: 0.1745 - val_accuracy: 0.9607\n",
      "Epoch 4/20\n",
      "86/86 [==============================] - 77s 899ms/step - loss: 0.2870 - accuracy: 0.8987 - val_loss: 0.0599 - val_accuracy: 0.9896\n",
      "Epoch 5/20\n",
      "86/86 [==============================] - 78s 906ms/step - loss: 0.1525 - accuracy: 0.9488 - val_loss: 0.0216 - val_accuracy: 0.9971\n",
      "Epoch 6/20\n",
      "86/86 [==============================] - 77s 898ms/step - loss: 0.1039 - accuracy: 0.9651 - val_loss: 0.0136 - val_accuracy: 0.9978\n",
      "Epoch 7/20\n",
      "86/86 [==============================] - 78s 903ms/step - loss: 0.0619 - accuracy: 0.9805 - val_loss: 0.0027 - val_accuracy: 0.9998\n",
      "Epoch 8/20\n",
      "86/86 [==============================] - 78s 904ms/step - loss: 0.0387 - accuracy: 0.9877 - val_loss: 9.2916e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "86/86 [==============================] - 77s 895ms/step - loss: 0.0324 - accuracy: 0.9900 - val_loss: 9.0861e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "86/86 [==============================] - 77s 898ms/step - loss: 0.0250 - accuracy: 0.9927 - val_loss: 4.8946e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "86/86 [==============================] - 78s 909ms/step - loss: 0.0226 - accuracy: 0.9930 - val_loss: 2.8843e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "86/86 [==============================] - 77s 898ms/step - loss: 0.0177 - accuracy: 0.9944 - val_loss: 4.3413e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "86/86 [==============================] - 78s 906ms/step - loss: 0.0185 - accuracy: 0.9944 - val_loss: 5.3518e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "86/86 [==============================] - 79s 915ms/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 2.6834e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "86/86 [==============================] - 77s 900ms/step - loss: 0.0148 - accuracy: 0.9958 - val_loss: 9.4990e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "86/86 [==============================] - 78s 911ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 2.3513e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "86/86 [==============================] - 77s 897ms/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 1.0572e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "86/86 [==============================] - 78s 902ms/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 1.8619e-04 - val_accuracy: 1.0000\n",
      "model6 accuracy =  0.97\n"
     ]
    }
   ],
   "source": [
    "#wywolanie modelu 6\n",
    "model6 = create_model(X_train, Y_train,[32, 64, 128 ,256], 0.2,[512,128],24, plot = False)\n",
    "\n",
    "#predykcja\n",
    "y_pred6 = model6.predict(X_test).argmax(axis = 1)\n",
    "\n",
    "acc6 = accuracy_score(y_pred6, Y_test.argmax(axis = 1))\n",
    "print('model6 accuracy = ', round(acc6,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114b8cb3",
   "metadata": {},
   "source": [
    "Dodając kolejną warstwe Conv2D nasz model nie poprawia dokładnosci, w kolejnym kroku sprobujmy wykorzystać metodę residual blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "b22a68c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definicja residual block:\n",
    "\n",
    "def res_block(input_, filters):\n",
    "    for i, j in enumerate(filters):\n",
    "        if i ==0:\n",
    "            x_1 = tf.keras.layers.Conv2D(filters= j, kernel_size = (3,3), padding = 'same')(input_)\n",
    "            x_1 = tf.keras.layers.ReLU()(x_1)\n",
    "            x_1 = tf.keras.layers.BatchNormalization()(x_1)\n",
    "            x_2 = tf.keras.layers.Conv2D(filters=j, kernel_size=(3,3), padding=\"same\")(x_1)\n",
    "        else:\n",
    "            x_1 = tf.keras.layers.Conv2D(filters=j, kernel_size = (3,3), padding = 'same')(x_1)\n",
    "            x_1 = tf.keras.layers.ReLU()(x_1)\n",
    "            x_1 = tf.keras.layers.BatchNormalization()(x_1)\n",
    "            x_2 = tf.keras.layers.Conv2D(filters=j, kernel_size=(3,3), padding=\"same\")(x_1)  \n",
    "    \n",
    "    output = tf.keras.layers.Add()([input_, x_2])\n",
    "    output = tf.keras.layers.ReLU()(output)\n",
    "    output = tf.keras.layers.BatchNormalization()(output)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "890e6f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#konstrukcja modelu \n",
    "input_shape = (28,28,1)\n",
    "\n",
    "input_layer = tf.keras.Input(shape=input_shape, dtype=tf.float32)\n",
    "\n",
    "resblock = res_block(input_layer, [32,64])\n",
    "\n",
    "avg_pool = tf.keras.layers.GlobalAveragePooling2D()(resblock)\n",
    "\n",
    "droput = tf.keras.layers.Dropout(0.2)(avg_pool)\n",
    "\n",
    "out = tf.keras.layers.Dense(24)(droput)\n",
    "out = tf.keras.layers.Softmax()(out)\n",
    "\n",
    "model7 = tf.keras.Model(\n",
    "    inputs = input_layer,\n",
    "    outputs = out,\n",
    "    name=\"model_with_residual_block\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "3b1d7b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_with_residual_block\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_27 (InputLayer)           [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 28, 28, 32)   320         input_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_38 (ReLU)                 (None, 28, 28, 32)   0           conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 28, 28, 32)   128         re_lu_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 28, 28, 64)   18496       batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_39 (ReLU)                 (None, 28, 28, 64)   0           conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 28, 28, 64)   256         re_lu_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 28, 28, 64)   36928       batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 28, 28, 64)   0           input_27[0][0]                   \n",
      "                                                                 conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_40 (ReLU)                 (None, 28, 28, 64)   0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 28, 28, 64)   256         re_lu_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 64)           0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 64)           0           global_average_pooling2d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 24)           1560        dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "softmax_11 (Softmax)            (None, 24)           0           dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 57,944\n",
      "Trainable params: 57,624\n",
      "Non-trainable params: 320\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "38b29dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "687/687 [==============================] - 219s 313ms/step - loss: 1.7097 - accuracy: 0.5227 - val_loss: 3.7878 - val_accuracy: 0.1674\n",
      "Epoch 2/30\n",
      "687/687 [==============================] - 215s 313ms/step - loss: 0.5949 - accuracy: 0.8615 - val_loss: 1.4017 - val_accuracy: 0.5851\n",
      "Epoch 3/30\n",
      "687/687 [==============================] - 215s 314ms/step - loss: 0.2637 - accuracy: 0.9512 - val_loss: 2.4634 - val_accuracy: 0.4782\n",
      "Epoch 4/30\n",
      "687/687 [==============================] - 221s 321ms/step - loss: 0.1326 - accuracy: 0.9807 - val_loss: 0.1819 - val_accuracy: 0.9536\n",
      "Epoch 5/30\n",
      "687/687 [==============================] - 228s 332ms/step - loss: 0.0795 - accuracy: 0.9893 - val_loss: 0.1536 - val_accuracy: 0.9563\n",
      "Epoch 6/30\n",
      "687/687 [==============================] - 244s 355ms/step - loss: 0.0448 - accuracy: 0.9960 - val_loss: 0.7272 - val_accuracy: 0.7835\n",
      "Epoch 7/30\n",
      "687/687 [==============================] - 216s 315ms/step - loss: 0.0475 - accuracy: 0.9924 - val_loss: 1.4104 - val_accuracy: 0.6742\n",
      "Epoch 8/30\n",
      "687/687 [==============================] - 216s 314ms/step - loss: 0.0278 - accuracy: 0.9961 - val_loss: 0.0571 - val_accuracy: 0.9876\n",
      "Epoch 9/30\n",
      "687/687 [==============================] - 216s 314ms/step - loss: 0.0335 - accuracy: 0.9938 - val_loss: 0.1228 - val_accuracy: 0.9594\n",
      "Epoch 10/30\n",
      "687/687 [==============================] - 216s 315ms/step - loss: 0.0181 - accuracy: 0.9974 - val_loss: 0.2276 - val_accuracy: 0.9206\n",
      "Epoch 11/30\n",
      "687/687 [==============================] - 215s 314ms/step - loss: 0.0218 - accuracy: 0.9957 - val_loss: 0.2839 - val_accuracy: 0.9033\n"
     ]
    }
   ],
   "source": [
    "#trening i walidacja\n",
    "\n",
    "model7.compile(\n",
    "    optimizer='Adam',\n",
    "    loss=  'categorical_crossentropy',\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "epochs = 30\n",
    "patience = 3\n",
    "history = model7.fit(\n",
    "    X_train, \n",
    "    Y_train,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(patience=patience)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "a4ca15db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model7 accuracy =  0.86\n"
     ]
    }
   ],
   "source": [
    "#predykcja\n",
    "y_pred7 = model7.predict(X_test).argmax(axis = 1)\n",
    "\n",
    "acc7 = accuracy_score(y_pred7, Y_test.argmax(axis = 1))\n",
    "print('model7 accuracy = ', round(acc7,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd78655",
   "metadata": {},
   "source": [
    "Nasz model nie poprawił swojej dokładnosci przy zastosowaniu residuals block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b158ba04",
   "metadata": {},
   "source": [
    "**Augmentacja danych**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6e3998b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poszerzmy nasz zbior o augmentacje\n",
    "## dodajmy nowe obserwacje obrócone w poziomie \n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.RandomFlip(\"horizontal_and_vertical\")\n",
    "])\n",
    "\n",
    "data_augmentation1 = tf.keras.Sequential([\n",
    "  layers.RandomRotation(0.5),\n",
    "  layers.RandomFlip(\"horizontal_and_vertical\")\n",
    "])\n",
    "\n",
    "augmentation =  lambda x, y: (data_augmentation(x, training=True), y)\n",
    "augmentation1 =  lambda x, y: (data_augmentation1(x, training=True), y)\n",
    "\n",
    "AUG = augmentation(X_train,Y_train)\n",
    "AUG1 = augmentation1(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "657963af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#przekonwertujmy to do array\n",
    "X_train_1 = AUG[0]\n",
    "Y_train_1 = AUG[1]\n",
    "\n",
    "X_train_2 = AUG1[0]\n",
    "Y_train_2 = AUG1[1]\n",
    "\n",
    "# połaczmy z naszym zbiorem X_train i Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d971ee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_aug = np.vstack([X_train, X_train_1,X_train_2])\n",
    "Y_train_aug =np.vstack([Y_train, Y_train_1, Y_train_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8134c7ab",
   "metadata": {},
   "source": [
    "**Wywołanie modelu na danych z augmentacja**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "dd354dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "warstwaCNN0 (MaxPooling2D)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "warstwaCNN1 (MaxPooling2D)   (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "warstwaCNN2 (MaxPooling2D)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "warstwa_gesta0 (Dense)       (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "warstwa_gesta1 (Dense)       (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "wyjscie (Dense)              (None, 24)                1560      \n",
      "_________________________________________________________________\n",
      "softmax_8 (Softmax)          (None, 24)                0         \n",
      "=================================================================\n",
      "Total params: 635,224\n",
      "Trainable params: 635,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "86/86 [==============================] - 57s 654ms/step - loss: 3.1794 - accuracy: 0.0473 - val_loss: 3.1762 - val_accuracy: 0.0461\n",
      "Epoch 2/20\n",
      "86/86 [==============================] - 49s 570ms/step - loss: 3.1614 - accuracy: 0.0587 - val_loss: 3.1288 - val_accuracy: 0.1038\n",
      "Epoch 3/20\n",
      "86/86 [==============================] - 60s 695ms/step - loss: 2.7156 - accuracy: 0.1725 - val_loss: 2.0200 - val_accuracy: 0.4272\n",
      "Epoch 4/20\n",
      "86/86 [==============================] - 56s 649ms/step - loss: 1.9319 - accuracy: 0.3592 - val_loss: 1.1335 - val_accuracy: 0.6922\n",
      "Epoch 5/20\n",
      "86/86 [==============================] - 56s 647ms/step - loss: 1.3601 - accuracy: 0.5253 - val_loss: 0.6939 - val_accuracy: 0.8390\n",
      "Epoch 6/20\n",
      "86/86 [==============================] - 58s 671ms/step - loss: 1.0219 - accuracy: 0.6433 - val_loss: 0.4281 - val_accuracy: 0.9177\n",
      "Epoch 7/20\n",
      "86/86 [==============================] - 52s 607ms/step - loss: 0.8237 - accuracy: 0.7104 - val_loss: 0.3170 - val_accuracy: 0.9301\n",
      "Epoch 8/20\n",
      "86/86 [==============================] - 55s 644ms/step - loss: 0.6944 - accuracy: 0.7581 - val_loss: 0.2358 - val_accuracy: 0.9510\n",
      "Epoch 9/20\n",
      "86/86 [==============================] - 53s 616ms/step - loss: 0.5864 - accuracy: 0.7952 - val_loss: 0.1725 - val_accuracy: 0.9634\n",
      "Epoch 10/20\n",
      "86/86 [==============================] - 57s 664ms/step - loss: 0.5177 - accuracy: 0.8217 - val_loss: 0.1506 - val_accuracy: 0.9707\n",
      "Epoch 11/20\n",
      "86/86 [==============================] - 49s 571ms/step - loss: 0.4549 - accuracy: 0.8447 - val_loss: 0.1158 - val_accuracy: 0.9756\n",
      "Epoch 12/20\n",
      "86/86 [==============================] - 49s 567ms/step - loss: 0.4112 - accuracy: 0.8590 - val_loss: 0.0940 - val_accuracy: 0.9825\n",
      "Epoch 13/20\n",
      "86/86 [==============================] - 47s 552ms/step - loss: 0.3723 - accuracy: 0.8732 - val_loss: 0.0800 - val_accuracy: 0.9842\n",
      "Epoch 14/20\n",
      "86/86 [==============================] - 44s 515ms/step - loss: 0.3535 - accuracy: 0.8823 - val_loss: 0.0662 - val_accuracy: 0.9883\n",
      "Epoch 15/20\n",
      "86/86 [==============================] - 45s 529ms/step - loss: 0.3218 - accuracy: 0.8943 - val_loss: 0.0510 - val_accuracy: 0.9911\n",
      "Epoch 16/20\n",
      "86/86 [==============================] - 48s 562ms/step - loss: 0.2916 - accuracy: 0.9014 - val_loss: 0.0391 - val_accuracy: 0.9940\n",
      "Epoch 17/20\n",
      "86/86 [==============================] - 47s 543ms/step - loss: 0.2684 - accuracy: 0.9134 - val_loss: 0.0323 - val_accuracy: 0.9951\n",
      "Epoch 18/20\n",
      "86/86 [==============================] - 42s 493ms/step - loss: 0.2521 - accuracy: 0.9189 - val_loss: 0.0300 - val_accuracy: 0.9947\n",
      "Epoch 19/20\n",
      "86/86 [==============================] - 50s 585ms/step - loss: 0.2410 - accuracy: 0.9244 - val_loss: 0.0222 - val_accuracy: 0.9956\n",
      "Epoch 20/20\n",
      "86/86 [==============================] - 50s 582ms/step - loss: 0.2233 - accuracy: 0.9291 - val_loss: 0.0174 - val_accuracy: 0.9987\n",
      "model7 accuracy =  0.97\n"
     ]
    }
   ],
   "source": [
    "#wywolanie modelu 7\n",
    "model7 = create_model(X_train, Y_train,[32, 64, 128], 0.5,[256,64],24, plot = False)\n",
    "\n",
    "#predykcja\n",
    "y_pred7 = model7.predict(X_test).argmax(axis = 1)\n",
    "\n",
    "acc7 = accuracy_score(y_pred7, Y_test.argmax(axis = 1))\n",
    "print('model7 accuracy = ', round(acc7,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95dbbd4",
   "metadata": {},
   "source": [
    "Podwyższony dropout i augmentacja danych nie podwyzszyła naszej osiaganego skutecznosci "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149dfa71",
   "metadata": {},
   "source": [
    "**Prezentacja wyników modeli w tensorboard**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "354e53b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 160), started 1 day, 16:58:01 ago. (Use '!kill 160' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a8e0ba4a878e1c12\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a8e0ba4a878e1c12\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir \"logs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1867166",
   "metadata": {},
   "source": [
    "**Zapiszmy nasz najlepszy model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "47577489",
   "metadata": {},
   "outputs": [],
   "source": [
    "#najlepszym modelem okazał się model4\n",
    "model4.save(\"model_dt/model_dt.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "84b81825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w dokumentacji napisz jaki to data set, skad pochodzi, daj obrazek, ze nie wszystkie litery sa\n",
    "#dokumentacje po angielsku\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
